{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term deposit marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import toml\n",
    "import pandas as pd\n",
    "\n",
    "import pycaret.classification as pycaret\n",
    "from IPython.display import display, Markdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Add sys to path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./term_deposit\")\n",
    "import term_deposit as td\n",
    "\n",
    "# Change the working directory to the root of the project\n",
    "while os.path.basename(cwd := os.getcwd()) != \"2-term_deposit_marketing\":\n",
    "    print(cwd)\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# Load the configuration file\n",
    "config = toml.load('config.toml')\n",
    "target = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 36 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   number_calls         40000 non-null  int64\n",
      " 1   y                    40000 non-null  int64\n",
      " 2   job_blue-collar      40000 non-null  uint8\n",
      " 3   job_entrepreneur     40000 non-null  uint8\n",
      " 4   job_housemaid        40000 non-null  uint8\n",
      " 5   job_management       40000 non-null  uint8\n",
      " 6   job_retired          40000 non-null  uint8\n",
      " 7   job_self-employed    40000 non-null  uint8\n",
      " 8   job_services         40000 non-null  uint8\n",
      " 9   job_student          40000 non-null  uint8\n",
      " 10  job_technician       40000 non-null  uint8\n",
      " 11  job_unemployed       40000 non-null  uint8\n",
      " 12  marital_married      40000 non-null  uint8\n",
      " 13  marital_single       40000 non-null  uint8\n",
      " 14  education_secondary  40000 non-null  uint8\n",
      " 15  education_tertiary   40000 non-null  uint8\n",
      " 16  default_yes          40000 non-null  uint8\n",
      " 17  housing_yes          40000 non-null  uint8\n",
      " 18  loan_yes             40000 non-null  uint8\n",
      " 19  contact_telephone    40000 non-null  uint8\n",
      " 20  month_aug            40000 non-null  uint8\n",
      " 21  month_dec            40000 non-null  uint8\n",
      " 22  month_feb            40000 non-null  uint8\n",
      " 23  month_jan            40000 non-null  uint8\n",
      " 24  month_jul            40000 non-null  uint8\n",
      " 25  month_jun            40000 non-null  uint8\n",
      " 26  month_mar            40000 non-null  uint8\n",
      " 27  month_may            40000 non-null  uint8\n",
      " 28  month_nov            40000 non-null  uint8\n",
      " 29  month_oct            40000 non-null  uint8\n",
      " 30  high_balance         40000 non-null  int8 \n",
      " 31  duration_q1          40000 non-null  uint8\n",
      " 32  duration_q2          40000 non-null  uint8\n",
      " 33  duration_q3          40000 non-null  uint8\n",
      " 34  age_group_18-30      40000 non-null  uint8\n",
      " 35  age_group_60+        40000 non-null  uint8\n",
      "dtypes: int64(2), int8(1), uint8(33)\n",
      "memory usage: 1.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_calls</th>\n",
       "      <th>y</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>high_balance</th>\n",
       "      <th>duration_q1</th>\n",
       "      <th>duration_q2</th>\n",
       "      <th>duration_q3</th>\n",
       "      <th>age_group_18-30</th>\n",
       "      <th>age_group_60+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32566</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28547</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6456</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_calls  y  job_blue-collar  job_entrepreneur  job_housemaid  \\\n",
       "32566             1  0                1                 0              0   \n",
       "28547             2  0                0                 0              0   \n",
       "6456              2  0                0                 0              0   \n",
       "\n",
       "       job_management  job_retired  job_self-employed  job_services  \\\n",
       "32566               0            0                  0             0   \n",
       "28547               1            0                  0             0   \n",
       "6456                0            0                  0             0   \n",
       "\n",
       "       job_student  job_technician  job_unemployed  marital_married  \\\n",
       "32566            0               0               0                1   \n",
       "28547            0               0               0                1   \n",
       "6456             0               0               1                0   \n",
       "\n",
       "       marital_single  education_secondary  education_tertiary  default_yes  \\\n",
       "32566               0                    1                   0            0   \n",
       "28547               0                    0                   1            0   \n",
       "6456                1                    1                   0            0   \n",
       "\n",
       "       housing_yes  loan_yes  contact_telephone  month_aug  month_dec  \\\n",
       "32566            1         0                  1          0          0   \n",
       "28547            1         0                  0          0          0   \n",
       "6456             1         0                  0          0          0   \n",
       "\n",
       "       month_feb  month_jan  month_jul  month_jun  month_mar  month_may  \\\n",
       "32566          0          0          0          0          0          0   \n",
       "28547          0          1          0          0          0          0   \n",
       "6456           0          0          0          0          0          1   \n",
       "\n",
       "       month_nov  month_oct  high_balance  duration_q1  duration_q2  \\\n",
       "32566          0          0             0            0            1   \n",
       "28547          0          0             0            0            0   \n",
       "6456           0          0             0            0            1   \n",
       "\n",
       "       duration_q3  age_group_18-30  age_group_60+  \n",
       "32566            0                0              0  \n",
       "28547            1                1              0  \n",
       "6456             0                1              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_calls</th>\n",
       "      <th>y</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>month_aug</th>\n",
       "      <th>month_dec</th>\n",
       "      <th>month_feb</th>\n",
       "      <th>month_jan</th>\n",
       "      <th>month_jul</th>\n",
       "      <th>month_jun</th>\n",
       "      <th>month_mar</th>\n",
       "      <th>month_may</th>\n",
       "      <th>month_nov</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>high_balance</th>\n",
       "      <th>duration_q1</th>\n",
       "      <th>duration_q2</th>\n",
       "      <th>duration_q3</th>\n",
       "      <th>age_group_18-30</th>\n",
       "      <th>age_group_60+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.00000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.882175</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.234575</td>\n",
       "      <td>0.035125</td>\n",
       "      <td>0.027175</td>\n",
       "      <td>0.204150</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>0.035350</td>\n",
       "      <td>0.09775</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.609650</td>\n",
       "      <td>0.272225</td>\n",
       "      <td>0.524825</td>\n",
       "      <td>0.280150</td>\n",
       "      <td>0.020225</td>\n",
       "      <td>0.600775</td>\n",
       "      <td>0.173250</td>\n",
       "      <td>0.058025</td>\n",
       "      <td>0.130375</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.029400</td>\n",
       "      <td>0.159500</td>\n",
       "      <td>0.118350</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.338300</td>\n",
       "      <td>0.089950</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.397950</td>\n",
       "      <td>0.335675</td>\n",
       "      <td>0.331925</td>\n",
       "      <td>0.332400</td>\n",
       "      <td>0.145975</td>\n",
       "      <td>0.005850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.239051</td>\n",
       "      <td>0.259152</td>\n",
       "      <td>0.423738</td>\n",
       "      <td>0.184098</td>\n",
       "      <td>0.162595</td>\n",
       "      <td>0.403084</td>\n",
       "      <td>0.186106</td>\n",
       "      <td>0.184665</td>\n",
       "      <td>0.29698</td>\n",
       "      <td>0.113704</td>\n",
       "      <td>0.376776</td>\n",
       "      <td>0.163826</td>\n",
       "      <td>0.487835</td>\n",
       "      <td>0.445111</td>\n",
       "      <td>0.499390</td>\n",
       "      <td>0.449078</td>\n",
       "      <td>0.140771</td>\n",
       "      <td>0.489745</td>\n",
       "      <td>0.378468</td>\n",
       "      <td>0.233794</td>\n",
       "      <td>0.336720</td>\n",
       "      <td>0.018025</td>\n",
       "      <td>0.232608</td>\n",
       "      <td>0.168927</td>\n",
       "      <td>0.366146</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.080053</td>\n",
       "      <td>0.473137</td>\n",
       "      <td>0.286114</td>\n",
       "      <td>0.044677</td>\n",
       "      <td>0.489481</td>\n",
       "      <td>0.472232</td>\n",
       "      <td>0.470910</td>\n",
       "      <td>0.471079</td>\n",
       "      <td>0.353086</td>\n",
       "      <td>0.076262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       number_calls             y  job_blue-collar  job_entrepreneur  \\\n",
       "count  40000.000000  40000.000000     40000.000000      40000.000000   \n",
       "mean       2.882175      0.072400         0.234575          0.035125   \n",
       "std        3.239051      0.259152         0.423738          0.184098   \n",
       "min        1.000000      0.000000         0.000000          0.000000   \n",
       "25%        1.000000      0.000000         0.000000          0.000000   \n",
       "50%        2.000000      0.000000         0.000000          0.000000   \n",
       "75%        3.000000      0.000000         0.000000          0.000000   \n",
       "max       63.000000      1.000000         1.000000          1.000000   \n",
       "\n",
       "       job_housemaid  job_management   job_retired  job_self-employed  \\\n",
       "count   40000.000000    40000.000000  40000.000000       40000.000000   \n",
       "mean        0.027175        0.204150      0.035925           0.035350   \n",
       "std         0.162595        0.403084      0.186106           0.184665   \n",
       "min         0.000000        0.000000      0.000000           0.000000   \n",
       "25%         0.000000        0.000000      0.000000           0.000000   \n",
       "50%         0.000000        0.000000      0.000000           0.000000   \n",
       "75%         0.000000        0.000000      0.000000           0.000000   \n",
       "max         1.000000        1.000000      1.000000           1.000000   \n",
       "\n",
       "       job_services   job_student  job_technician  job_unemployed  \\\n",
       "count   40000.00000  40000.000000    40000.000000    40000.000000   \n",
       "mean        0.09775      0.013100        0.171300        0.027600   \n",
       "std         0.29698      0.113704        0.376776        0.163826   \n",
       "min         0.00000      0.000000        0.000000        0.000000   \n",
       "25%         0.00000      0.000000        0.000000        0.000000   \n",
       "50%         0.00000      0.000000        0.000000        0.000000   \n",
       "75%         0.00000      0.000000        0.000000        0.000000   \n",
       "max         1.00000      1.000000        1.000000        1.000000   \n",
       "\n",
       "       marital_married  marital_single  education_secondary  \\\n",
       "count     40000.000000    40000.000000         40000.000000   \n",
       "mean          0.609650        0.272225             0.524825   \n",
       "std           0.487835        0.445111             0.499390   \n",
       "min           0.000000        0.000000             0.000000   \n",
       "25%           0.000000        0.000000             0.000000   \n",
       "50%           1.000000        0.000000             1.000000   \n",
       "75%           1.000000        1.000000             1.000000   \n",
       "max           1.000000        1.000000             1.000000   \n",
       "\n",
       "       education_tertiary   default_yes   housing_yes      loan_yes  \\\n",
       "count        40000.000000  40000.000000  40000.000000  40000.000000   \n",
       "mean             0.280150      0.020225      0.600775      0.173250   \n",
       "std              0.449078      0.140771      0.489745      0.378468   \n",
       "min              0.000000      0.000000      0.000000      0.000000   \n",
       "25%              0.000000      0.000000      0.000000      0.000000   \n",
       "50%              0.000000      0.000000      1.000000      0.000000   \n",
       "75%              1.000000      0.000000      1.000000      0.000000   \n",
       "max              1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       contact_telephone     month_aug     month_dec     month_feb  \\\n",
       "count       40000.000000  40000.000000  40000.000000  40000.000000   \n",
       "mean            0.058025      0.130375      0.000325      0.057400   \n",
       "std             0.233794      0.336720      0.018025      0.232608   \n",
       "min             0.000000      0.000000      0.000000      0.000000   \n",
       "25%             0.000000      0.000000      0.000000      0.000000   \n",
       "50%             0.000000      0.000000      0.000000      0.000000   \n",
       "75%             0.000000      0.000000      0.000000      0.000000   \n",
       "max             1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          month_jan     month_jul     month_jun     month_mar     month_may  \\\n",
       "count  40000.000000  40000.000000  40000.000000  40000.000000  40000.000000   \n",
       "mean       0.029400      0.159500      0.118350      0.006450      0.338300   \n",
       "std        0.168927      0.366146      0.323026      0.080053      0.473137   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          month_nov     month_oct  high_balance   duration_q1   duration_q2  \\\n",
       "count  40000.000000  40000.000000  40000.000000  40000.000000  40000.000000   \n",
       "mean       0.089950      0.002000      0.397950      0.335675      0.331925   \n",
       "std        0.286114      0.044677      0.489481      0.472232      0.470910   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      1.000000      1.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "        duration_q3  age_group_18-30  age_group_60+  \n",
       "count  40000.000000     40000.000000   40000.000000  \n",
       "mean       0.332400         0.145975       0.005850  \n",
       "std        0.471079         0.353086       0.076262  \n",
       "min        0.000000         0.000000       0.000000  \n",
       "25%        0.000000         0.000000       0.000000  \n",
       "50%        0.000000         0.000000       0.000000  \n",
       "75%        1.000000         0.000000       0.000000  \n",
       "max        1.000000         1.000000       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_parquet(config['paths'][\"data\"]['post'])\n",
    "\n",
    "# Display basic information about the dataset\n",
    "df.info(), display(df.sample(3)), display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding and balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df.drop('y', axis=1)\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=df[target], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e142f_row8_col1, #T_e142f_row15_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e142f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e142f_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_e142f_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e142f_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_e142f_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e142f_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_e142f_row1_col1\" class=\"data row1 col1\" >y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e142f_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_e142f_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e142f_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_e142f_row3_col1\" class=\"data row3 col1\" >(40000, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e142f_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_e142f_row4_col1\" class=\"data row4 col1\" >(40000, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e142f_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_e142f_row5_col1\" class=\"data row5 col1\" >(28000, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e142f_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_e142f_row6_col1\" class=\"data row6 col1\" >(12000, 36)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e142f_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_e142f_row7_col1\" class=\"data row7 col1\" >35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e142f_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_e142f_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e142f_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_e142f_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_e142f_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_e142f_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_e142f_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_e142f_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_e142f_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_e142f_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_e142f_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_e142f_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_e142f_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_e142f_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_e142f_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_e142f_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_e142f_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_e142f_row16_col1\" class=\"data row16 col1\" >MlflowLogger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_e142f_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_e142f_row17_col1\" class=\"data row17 col1\" >predict-term_deposit-marketing-2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e142f_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_e142f_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_e142f_row18_col1\" class=\"data row18 col1\" >eec0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2181071d7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3050 Laptop GPU, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 16 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Warning] GPU acceleration is disabled because no non-trivial dense features can be found\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    }
   ],
   "source": [
    "# Initialize PyCaret with the balanced data\n",
    "clf = pycaret.setup(data=X, target=y,\n",
    "            use_gpu=True, session_id=123,\n",
    "            log_experiment = True, experiment_name = 'predict-term_deposit-marketing-2020',\n",
    "            fix_imbalance_method=\"smote_tomek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_class_1_function(y_true, y_pred, **kwargs):\n",
    "    from sklearn.metrics import recall_score\n",
    "    # Print or log y_pred to check if class 1 is being predicted\n",
    "    print(\"y_pred distribution:\", pd.Series(y_pred).value_counts())  # Logging prediction distribution\n",
    "    return recall_score(y_true, y_pred, pos_label=1, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "WARNING:root:Malformed experiment 'post'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\post\\meta.yaml' does not exist.\n",
      "WARNING:root:Malformed experiment 'pre'. Detailed error Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 327, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 421, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1367, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py\", line 1360, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\mlflow\\utils\\file_utils.py\", line 309, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file 'C:\\Users\\Guill\\repos\\Apziva\\2-term_deposit_marketing\\mlruns\\pre\\meta.yaml' does not exist.\n",
      "2024/10/07 00:06:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Add the custom metric to PyCaret\n",
    "pycaret.add_metric(\n",
    "    id='recall_class_1',              # Unique identifier for the metric\n",
    "    name='Recall Class 1',            # Display name\n",
    "    score_func=recall_class_1_function, # The scoring function defined above\n",
    "    greater_is_better=True,            # Recall should be maximized\n",
    "    target='pred',                     # The target is the prediction, not probabilities\n",
    "    multiclass=False                   # Not using multiclass, focus is on binary recall\n",
    ")\n",
    "best_model = pycaret.compare_models(\n",
    "    sort='Recall Class 1',  # Sort models by the custom recall metric\n",
    "    verbose=False           # Do not print out all the logs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>00:06:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Searching Hyperparameters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Logistic Regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         \n",
       "                                                                         \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                   00:06:39\n",
       "Status     . . . . . . . . . . . . . . . . . .  Searching Hyperparameters\n",
       "Estimator  . . . . . . . . . . . . . . . . . .        Logistic Regression"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9beb614007af44ecb14ba5d33d5770e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mpycaret\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall_class_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcustom_scorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall_class_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;66;43;03m#  threshold=0.3\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\pycaret\\classification\\functional.py:1208\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1019\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1038\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \n\u001b[0;32m   1206\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CURRENT_EXPERIMENT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_scorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_library\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_library\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchoose_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_better\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tuner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tuner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtuner_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuner_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\pycaret\\classification\\oop.py:1558\u001b[0m, in \u001b[0;36mClassificationExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(\n\u001b[0;32m   1368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1369\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1388\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m    This function tunes the hyperparameters of a given estimator. The output of\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03m    this function is a score grid with CV scores by fold of the best selected\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1555\u001b[0m \n\u001b[0;32m   1556\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_scorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_library\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_library\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_algorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch_algorithm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_max_iters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchoose_better\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoose_better\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tuner\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tuner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtuner_verbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuner_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:2680\u001b[0m, in \u001b[0;36m_SupervisedExperiment.tune_model\u001b[1;34m(self, estimator, fold, round, n_iter, custom_grid, optimize, custom_scorer, search_library, search_algorithm, early_stopping, early_stopping_max_iters, choose_better, fit_kwargs, groups, return_tuner, verbose, tuner_verbose, return_train_score, **kwargs)\u001b[0m\n\u001b[0;32m   2672\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[0;32m   2673\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.sample_without_replacement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2674\u001b[0m         pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_sample_without_replacement,\n\u001b[0;32m   2675\u001b[0m     ):\n\u001b[0;32m   2676\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m patch(\n\u001b[0;32m   2677\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msklearn.model_selection._search.ParameterGrid.__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2678\u001b[0m             pycaret\u001b[38;5;241m.\u001b[39minternal\u001b[38;5;241m.\u001b[39mpatches\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39m_mp_ParameterGrid_getitem,\n\u001b[0;32m   2679\u001b[0m         ):\n\u001b[1;32m-> 2680\u001b[0m             \u001b[43mmodel_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2682\u001b[0m     model_grid\u001b[38;5;241m.\u001b[39mfit(data_X, data_y, groups\u001b[38;5;241m=\u001b[39mgroups, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "tuned_model = pycaret.tune_model(best_model, optimize='recall_class_1',\n",
    "                                 custom_scorer='recall_class_1',\n",
    "                                #  threshold=0.3\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/19 09:23:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "final_model = pycaret.finalize_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.44      0.61      7421\n",
      "           1       0.10      0.81      0.18       579\n",
      "\n",
      "    accuracy                           0.47      8000\n",
      "   macro avg       0.53      0.63      0.39      8000\n",
      "weighted avg       0.90      0.47      0.57      8000\n",
      "\n",
      "0.6253967234373629\n",
      "y_pred distribution: 1    4619\n",
      "0    3381\n",
      "Name: prediction_label, dtype: int64\n",
      "0.8100172711571675\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=Memory(location=None),\n",
       "          steps=[('numerical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include=['age', 'balance', 'day',\n",
       "                                              'duration', 'campaign'],\n",
       "                                     transformer=SimpleImputer(add_indicator=False,\n",
       "                                                               copy=True,\n",
       "                                                               fill_value=None,\n",
       "                                                               keep_empty_features=False,\n",
       "                                                               missing_values=nan,\n",
       "                                                               strategy='mean'))),\n",
       "                 ('categorical_imputer',\n",
       "                  TransformerWrapper(exclude=None,\n",
       "                                     include...\n",
       "                                     include=['job', 'marital', 'education',\n",
       "                                              'contact', 'month'],\n",
       "                                     transformer=OneHotEncoder(cols=['job',\n",
       "                                                                     'marital',\n",
       "                                                                     'education',\n",
       "                                                                     'contact',\n",
       "                                                                     'month'],\n",
       "                                                               drop_invariant=False,\n",
       "                                                               handle_missing='return_nan',\n",
       "                                                               handle_unknown='value',\n",
       "                                                               return_df=True,\n",
       "                                                               use_cat_names=True,\n",
       "                                                               verbose=0))),\n",
       "                 ('actual_estimator',\n",
       "                  QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
       "                                                store_covariance=False,\n",
       "                                                tol=0.0001))],\n",
       "          verbose=False),\n",
       " '../models/pyCaret/term_deposit_model.pkl')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Predict using the final model\n",
    "predictions = pycaret.predict_model(final_model, data=X_test)\n",
    "\n",
    "print(classification_report(y_test, predictions['prediction_label']))\n",
    "print(roc_auc_score(y_test, predictions['prediction_label']))\n",
    "print(td.recall_class_1_function(y_test, predictions['prediction_label']))\n",
    "\n",
    "confusion_matrix(y_test, predictions['prediction_label'])\n",
    "\n",
    "# Save the final model\n",
    "pathlib.Path(\"../models/pyCaret/term_deposit_model\").mkdir(\n",
    "    parents=True, exist_ok=True\n",
    ")\n",
    "pycaret.save_model(final_model, '../models/pyCaret/term_deposit_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 22.0.2+9-70, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\Guill\\miniconda3\\envs\\term_deposit-post\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Guill\\AppData\\Local\\Temp\\tmpo_ia4m5y\n",
      "  JVM stdout: C:\\Users\\Guill\\AppData\\Local\\Temp\\tmpo_ia4m5y\\h2o_Guill_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Guill\\AppData\\Local\\Temp\\tmpo_ia4m5y\\h2o_Guill_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Mexico_City</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.5</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 7 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Guill_x5gsqo</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.839 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>0</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.10 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         02 secs\n",
       "H2O_cluster_timezone:       America/Mexico_City\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.5\n",
       "H2O_cluster_version_age:    1 month and 7 days\n",
       "H2O_cluster_name:           H2O_from_python_Guill_x5gsqo\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.839 Gb\n",
       "H2O_cluster_total_cores:    0\n",
       "H2O_cluster_allowed_cores:  0\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.10 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || (done) 100%\n",
      "Parse progress: || (done) 100%\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "# Start the H2O cluster (locally)\n",
    "h2o.init()\n",
    "conf_H2O = config['settings'].get('H2O')\n",
    "\n",
    "# Convert your balanced train data to H2OFrame\n",
    "df_train = pd.concat([X_train, y_train], axis=1)  # Combine features and target\n",
    "df_test = pd.concat([X_test, y_test], axis=1)    # Combine features and target\n",
    "\n",
    "# Define target variable\n",
    "y = 'target'\n",
    "\n",
    "# Convert your data\n",
    "train = h2o.H2OFrame(df_train)\n",
    "test = h2o.H2OFrame(df_test)\n",
    "\n",
    "# Ensure response is a factor for binary classification\n",
    "train[target] = train[target].asfactor()\n",
    "test[target] = test[target].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>19 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/Mexico_City</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.5</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 7 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Guill_x5gsqo</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.820 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.10 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         19 secs\n",
       "H2O_cluster_timezone:       America/Mexico_City\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.5\n",
       "H2O_cluster_version_age:    1 month and 7 days\n",
       "H2O_cluster_name:           H2O_from_python_Guill_x5gsqo\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.820 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.10 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |\n",
      "00:08:23.731: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      " (cancelled) 100%\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Initialize H2O\n",
    "h2o.init()\n",
    "\n",
    "# Define a custom recall function for class 1\n",
    "class CustomRecallFunc:\n",
    "    def map(self, pred, act, w, o, model):\n",
    "        # Calculate recall for class 1\n",
    "        true_positives = sum((act == 1) & (pred == 1))\n",
    "        false_negatives = sum((act == 1) & (pred == 0))\n",
    "        return [true_positives, true_positives + false_negatives]\n",
    "\n",
    "    def reduce(self, l, r):\n",
    "        return [l[0] + r[0], l[1] + r[1]]\n",
    "\n",
    "    def metric(self, l):\n",
    "        return l[0] / l[1] if l[1] > 0 else 0  # Recall = TP / (TP + FN)\n",
    "\n",
    "# Upload the custom metric\n",
    "custom_recall_func = h2o.upload_custom_metric(CustomRecallFunc, func_name=\"recall_class_1\")\n",
    "\n",
    "# Run AutoML for 20 base models with custom recall metric\n",
    "aml = H2OAutoML(custom_metric_func=custom_recall_func, **conf_H2O)\n",
    "aml.train(x=list(X_train.columns), y=target, training_frame=train)\n",
    "\n",
    "# View the AutoML Leaderboard\n",
    "lb = aml.leaderboard\n",
    "lb = lb.sort(\"recall_class_1\", ascending=False)  # Sort by custom recall metric\n",
    "display(Markdown('## H2O Leaderboard'))\n",
    "display(lb.head(rows=lb.nrows))\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = aml.leader.predict(test)\n",
    "display(Markdown('## Predictions'))\n",
    "display(predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mc_plot \u001b[38;5;241m=\u001b[39m \u001b[43maml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_correlation_heatmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\explanation\\_explain.py:2277\u001b[0m, in \u001b[0;36mmodel_correlation_heatmap\u001b[1;34m(models, frame, top_n, cluster_models, triangular, figsize, colormap, save_plot_path)\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(models, h2o\u001b[38;5;241m.\u001b[39mautoml\u001b[38;5;241m.\u001b[39m_base\u001b[38;5;241m.\u001b[39mH2OAutoMLBaseMixin):\n\u001b[0;32m   2276\u001b[0m     models \u001b[38;5;241m=\u001b[39m _check_deprecated_top_n_argument(models, top_n)\n\u001b[1;32m-> 2277\u001b[0m corr, model_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcluster_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   2279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m triangular:\n\u001b[0;32m   2280\u001b[0m     corr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39mtriu(np\u001b[38;5;241m.\u001b[39mones_like(corr), k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m), \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m), corr)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\explanation\\_explain.py:2344\u001b[0m, in \u001b[0;36mmodel_correlation\u001b[1;34m(models, frame, cluster_models, use_pandas)\u001b[0m\n\u001b[0;32m   2342\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models)):\n\u001b[0;32m   2343\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m j:\n\u001b[1;32m-> 2344\u001b[0m                 corr[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2345\u001b[0m                 corr[j, i] \u001b[38;5;241m=\u001b[39m corr[i, j]\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:3049\u001b[0m, in \u001b[0;36mH2OFrame.mean\u001b[1;34m(self, skipna, axis, **kwargs)\u001b[0m\n\u001b[0;32m   3047\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_frame\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:819\u001b[0m, in \u001b[0;36mH2OFrame.getrow\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetrow\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    793\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;124;03m    Convert a 1xn frame into an n-element list.\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;124;03m    >>> means\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnrows\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m H2OValueError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis method can only be applied to single-row frames\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ExprNode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_eager_scalar()\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:325\u001b[0m, in \u001b[0;36mH2OFrame.nrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mnrows_valid():\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m--> 325\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfill_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mnrows\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:582\u001b[0m, in \u001b[0;36mH2OFrame._frame\u001b[1;34m(self, rows, rows_offset, cols, cols_offset, fill_cache)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m, rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, rows_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cols_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, fill_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 582\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eager_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_cache:\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mfill(rows\u001b[38;5;241m=\u001b[39mrows, rows_offset\u001b[38;5;241m=\u001b[39mrows_offset, cols\u001b[38;5;241m=\u001b[39mcols, cols_offset\u001b[38;5;241m=\u001b[39mcols_offset)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\expr.py:90\u001b[0m, in \u001b[0;36mExprNode._eager_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mis_empty(): \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# Data already computed under ID, but not cached locally\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\expr.py:114\u001b[0m, in \u001b[0;36mExprNode._eval_driver\u001b[1;34m(self, top)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m:param top: if this is a top expression (providing a final result),\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    then specifies the expected result type (accepted values = ['frame', 'scalar']),\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    or None if no object creation is expected.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m:return: self expr\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m exec_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ast_str(top)\n\u001b[1;32m--> 114\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mExprNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrapids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\expr.py:258\u001b[0m, in \u001b[0;36mExprNode.rapids\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrapids\u001b[39m(expr):\n\u001b[0;32m    251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m    Execute a Rapids expression.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    :returns: The JSON response (as a python dictionary) of the Rapids execution\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST /99/Rapids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msession_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mh2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\h2o.py:123\u001b[0m, in \u001b[0;36mapi\u001b[1;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# type checks are performed in H2OConnection class\u001b[39;00m\n\u001b[0;32m    122\u001b[0m _check_connection()\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh2oconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\backend\\connection.py:494\u001b[0m, in \u001b[0;36mH2OConnection.request\u001b[1;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_start_transaction(endpoint, rd, json, filename, params)\n\u001b[0;32m    493\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_args()\n\u001b[1;32m--> 494\u001b[0m resp \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, data\u001b[38;5;241m=\u001b[39mrd, json\u001b[38;5;241m=\u001b[39mjson, params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    495\u001b[0m                         stream\u001b[38;5;241m=\u001b[39mstream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(save_to, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[0;32m    497\u001b[0m     save_to \u001b[38;5;241m=\u001b[39m save_to(resp)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\urllib3\\connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\http\\client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1278\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\http\\client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1038\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1041\u001b[0m \n\u001b[0;32m   1042\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1044\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\http\\client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m--> 976\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_connected_to_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[0;32m     75\u001b[0m err \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mc_plot = aml.model_correlation_heatmap(\n",
    "    frame=test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or if some subset of the models is needed a slice of leaderboard can be used, e.g., using MAE as the sorting metric\n",
    "mc_plot = h2o.model_correlation_heatmap(aml.leaderboard.sort(\"mae\").head(10), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or even extended leaderboard can be used\n",
    "mc_plot = h2o.model_correlation_heatmap(h2o.automl.get_leaderboard(aml, extra_columns=\"training_time_ms\").sort(\"training_time_ms\").head(10), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also more complicated queries on leaderboard can be used, e.g., model correlation between 5 fastest models to train and Stacked Ensembles\n",
    "leaderboard = h2o.automl.get_leaderboard(aml, extra_columns=\"training_time_ms\").sort(\"training_time_ms\")\n",
    "mc_plot = h2o.model_correlation_heatmap(leaderboard.head(5).rbind(leaderboard[leaderboard[\"model_id\"].grep(\"StackedEnsemble\", output_logical=True)]), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: || (done) 100%\n"
     ]
    },
    {
     "ename": "H2OResponseError",
     "evalue": "Server error java.lang.IllegalArgumentException:\n  Error: Column None not found\n  Request: POST /99/Rapids\n    data: {'ast': \"(tmp= py_18_sid_ab3e (unique (cols_py Key_Frame__upload_984acee654effc263cd4fb4f81a44444.hex 'None') False))\", 'session_id': '_sid_ab3e'}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OResponseError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[213], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfair_shap_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mh2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mH2OFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test_processed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mprotected_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNone\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\model\\extensions\\fairness.py:369\u001b[0m, in \u001b[0;36mFairness.fair_shap_plot\u001b[1;34m(self, frame, column, protected_columns, autoscale, figsize, jitter, alpha, save_plot_path_prefix, background_frame)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mh2o\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_matplotlib_pyplot\n\u001b[0;32m    368\u001b[0m plt \u001b[38;5;241m=\u001b[39m get_matplotlib_pyplot(\u001b[38;5;28;01mFalse\u001b[39;00m, raise_if_not_available\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 369\u001b[0m pgs \u001b[38;5;241m=\u001b[39m product(\u001b[38;5;241m*\u001b[39m[frame[col]\u001b[38;5;241m.\u001b[39munique()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mas_data_frame(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m protected_columns])\n\u001b[0;32m    370\u001b[0m results \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    371\u001b[0m maxes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\model\\extensions\\fairness.py:369\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mh2o\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_matplotlib_pyplot\n\u001b[0;32m    368\u001b[0m plt \u001b[38;5;241m=\u001b[39m get_matplotlib_pyplot(\u001b[38;5;28;01mFalse\u001b[39;00m, raise_if_not_available\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 369\u001b[0m pgs \u001b[38;5;241m=\u001b[39m product(\u001b[38;5;241m*\u001b[39m[\u001b[43mframe\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mas_data_frame(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m protected_columns])\n\u001b[0;32m    370\u001b[0m results \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[0;32m    371\u001b[0m maxes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:2115\u001b[0m, in \u001b[0;36mH2OFrame.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2113\u001b[0m     item \u001b[38;5;241m=\u001b[39m normalize_slice(item, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mncols)\n\u001b[0;32m   2114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_type(item, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mslice\u001b[39m):\n\u001b[1;32m-> 2115\u001b[0m     new_ncols, new_names, new_types, item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_ncol_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2116\u001b[0m     new_nrows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrow\n\u001b[0;32m   2117\u001b[0m     fr \u001b[38;5;241m=\u001b[39m H2OFrame\u001b[38;5;241m.\u001b[39m_expr(expr\u001b[38;5;241m=\u001b[39mExprNode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcols_py\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, item))\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:2187\u001b[0m, in \u001b[0;36mH2OFrame._compute_ncol_update\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_type(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   2186\u001b[0m     new_names \u001b[38;5;241m=\u001b[39m [item]\n\u001b[1;32m-> 2187\u001b[0m     new_types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m {item: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes[item]}\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2189\u001b[0m     new_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames[item]]\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:374\u001b[0m, in \u001b[0;36mH2OFrame.types\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mtypes_valid():\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfill_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mtypes)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\frame.py:582\u001b[0m, in \u001b[0;36mH2OFrame._frame\u001b[1;34m(self, rows, rows_offset, cols, cols_offset, fill_cache)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_frame\u001b[39m(\u001b[38;5;28mself\u001b[39m, rows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, rows_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, cols_offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, fill_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 582\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eager_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_cache:\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ex\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mfill(rows\u001b[38;5;241m=\u001b[39mrows, rows_offset\u001b[38;5;241m=\u001b[39mrows_offset, cols\u001b[38;5;241m=\u001b[39mcols, cols_offset\u001b[38;5;241m=\u001b[39mcols_offset)\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\expr.py:90\u001b[0m, in \u001b[0;36mExprNode._eager_frame\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mis_empty(): \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m  \u001b[38;5;66;03m# Data already computed under ID, but not cached locally\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval_driver\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\expr.py:114\u001b[0m, in \u001b[0;36mExprNode._eval_driver\u001b[1;34m(self, top)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m:param top: if this is a top expression (providing a final result),\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m    then specifies the expected result type (accepted values = ['frame', 'scalar']),\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    or None if no object creation is expected.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m:return: self expr\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    113\u001b[0m exec_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ast_str(top)\n\u001b[1;32m--> 114\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mExprNode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrapids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\expr.py:258\u001b[0m, in \u001b[0;36mExprNode.rapids\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrapids\u001b[39m(expr):\n\u001b[0;32m    251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;124;03m    Execute a Rapids expression.\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    :returns: The JSON response (as a python dictionary) of the Rapids execution\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST /99/Rapids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msession_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mh2o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\h2o.py:123\u001b[0m, in \u001b[0;36mapi\u001b[1;34m(endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# type checks are performed in H2OConnection class\u001b[39;00m\n\u001b[0;32m    122\u001b[0m _check_connection()\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mh2oconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\backend\\connection.py:499\u001b[0m, in \u001b[0;36mH2OConnection.request\u001b[1;34m(self, endpoint, data, json, filename, save_to)\u001b[0m\n\u001b[0;32m    497\u001b[0m         save_to \u001b[38;5;241m=\u001b[39m save_to(resp)\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_end_transaction(start_time, resp)\n\u001b[1;32m--> 499\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mConnectionError, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_server \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_server\u001b[38;5;241m.\u001b[39mis_running():\n",
      "File \u001b[1;32mc:\\Users\\Guill\\miniconda3\\envs\\term_deposit\\lib\\site-packages\\h2o\\backend\\connection.py:853\u001b[0m, in \u001b[0;36mH2OConnection._process_response\u001b[1;34m(response, save_to)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status_code \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m404\u001b[39m, \u001b[38;5;241m412\u001b[39m} \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, H2OErrorV3):\n\u001b[0;32m    852\u001b[0m     data\u001b[38;5;241m.\u001b[39mshow_stacktrace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 853\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m H2OResponseError(data)\n\u001b[0;32m    855\u001b[0m \u001b[38;5;66;03m# Server errors (notably 500 = \"Server Error\")\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# Note that it is possible to receive valid H2OErrorV3 object in this case, however it merely means the server\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# did not provide the correct status code.\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m H2OServerError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (status_code, response\u001b[38;5;241m.\u001b[39mreason, data))\n",
      "\u001b[1;31mH2OResponseError\u001b[0m: Server error java.lang.IllegalArgumentException:\n  Error: Column None not found\n  Request: POST /99/Rapids\n    data: {'ast': \"(tmp= py_18_sid_ab3e (unique (cols_py Key_Frame__upload_984acee654effc263cd4fb4f81a44444.hex 'None') False))\", 'session_id': '_sid_ab3e'}\n"
     ]
    }
   ],
   "source": [
    "aml.leader.fair_shap_plot(frame=test,\n",
    "                          column='target',\n",
    "                          protected_columns=[\"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "term_deposit-post",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
